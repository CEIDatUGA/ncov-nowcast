---
title: "Backcasting with Deconvolution"
author: "Eric Marty, Tim Wildauer"
output:
  html_document:
    df_print: paged
---

# Current Outbreak Data

```{r warning=FALSE, message=FALSE}

library(tidyverse)
library(tibbletime)

source('R/package.R'); source('R/deconcolve.R'); source('R/simple_tdar.R');

## also possible to link directly to google sheet. see mosaic::fetchGoogle(), requires publishing sheet
china_province_data_cases <- read.csv("data/china_province_data_cases.csv",stringsAsFactors = FALSE)

cases <- china_province_data_cases %>% 
  select(-Type) %>% 
  mutate(Date = parse_date(Date,format="%m-%d-%Y")) %>% 
  drop_na(Date) %>% 
  tibbletime::as_tbl_time(index=Date) %>% 
  mutate(China = rowSums(.[,-1],na.rm = TRUE))

#cases.totals <- china_province_data_cases %>% 
#  select(-Type) %>%
#  filter(grepl("totals",Date)) %>% 
#  rename(Totals = Date) %>% 
#  mutate(China = rowSums(.[,-1],na.rm = TRUE))

#cases.totals

#cases.totals %>% select(Totals, China)

plot(x=cases$Date,y=cases$China,type="o",pch=20,cex=.7,log='y')

```


```{r}

# set up container

china <- cases %>% select(Date, cases = China)

# set December 01, 2019 as day 1
allchina=c(rep(0, times=30), china[["cases"]])

# Function for putting all decovolutions into a curve.
make_df = function(deconvolutions, skip="none"){
  results=cbind(simple=deconvolutions$simple)
  if(!("random" %in% skip)) results=cbind(results, random=deconvolutions$random)
  if(!("ridge" %in% skip)) results=cbind(results, ridge=deconvolutions$ridge)
  if(!("rl" %in% skip)) results=cbind(results, rl=deconvolutions$rl)
  if(!("fourier" %in% skip)) results=cbind(results, fourier=deconvolutions$fourier)
  if(!("frequency" %in% skip)) results=cbind(results, frequency=deconvolutions$frequency)
  if(!("average" %in% skip)) results=cbind(results, average=deconvolutions$average)
  return(results)
}
```

# Deconvolution overview

During the early stages of the outbreak, we were able to estimate the incubation period. Deconvolving the curve with just the incubation period is easy. However, if we use officially confirmed cases, we need to take into account the time between symptom onset and case confirmation. The distribution for this time changes throughout the early stages of the outbreak. Because there are two different time delays, we need two separate deconvolutions. First we will deconvolve the time variable portion, and then the incubation period.

## Symptom-onset to case confirmation

There are four different stages of the outbreak. Pre-January 9, January 9 to January 18, January 19 to January 23, and post-January 23. These timeframes are defined by Paige in https://docs.google.com/document/d/1GpTvsoTZBWphn2tLbKHE5Z1ZE8RuD3caTHar-DqtqHc/edit?pli=1. The time between onset of symptoms and confirmation is distinct between these time frames. We deconvolve the curve three times for each of the time frames and concatenate them together. Deconvolving these individually and concatenating them is imperfect, but given the amount of uncertainty surrounding the outbreak as a whole, it is sufficient for now. A rigorous solution for this is in the works.

```{r}
# index 39 is January 08
# index 40 is January 09
# index 49 is January 18
# index 50 is January 19
# index 53 is January 22
# index 54 is January 23
parms <- c(6.57,4.78)
distribution <- "gamma"
janpre09=deconvolve_single_curve(curve=allchina, parms = parms, skip="fourier")
janpre09 = make_df(janpre09, skip = "fourier")
parms <- c(4.77,3.11)
jan09_19=deconvolve_single_curve(curve=allchina, parms = parms, skip="fourier")
jan09_19 = make_df(jan09_19, skip = "fourier")
parms <- c(0.812,1,12)
jan19_23=deconvolve_single_curve(curve=allchina, parms = parms, skip="fourier")
jan19_23 = make_df(jan19_23, skip = "fourier")

final_curve = rbind(janpre09[1:39,], jan09_19[40:49,], jan19_23[50:53,], cbind( allchina[54:length(allchina)]
                                                                               ,allchina[54:length(allchina)]
                                                                               ,allchina[54:length(allchina)]
                                                                               ,allchina[54:length(allchina)]
                                                                               ,allchina[54:length(allchina)]
                                                                               #,allchina[54:length(allchina)]
                                                                               ,allchina[54:length(allchina)]))


# Breaking the deconvolution into stages like this is not perfect and creates jagged edges. Run a moving average to smooth out the sharp edges.
weights <- (1/9)*c(1, 2, 3, 2, 1)
for (i in 1:6) {
  final_curve[,i] = c(0,0,stats::filter(final_curve[,i]
                                        , filter=weights
                                        , sides=2)[3:(length(final_curve[,i])-2)]
                      , final_curve[,i][(length(final_curve[,i])-1):length(final_curve[,i])])
}

```


## Symptom-onset to Infection

Now we have a rough estimate of the number of people beginning to show symptoms each day. Deconvolution to get the number of people infected each day is straightforward. We will skip a number of different deconvolution methods because they are not reliable. Random requires a longer symptom-onset curve to get accurate infections, ridge is not good in this short of an outbreak with this mean/sd for the incubation period, fourier is not that great with a truncated infection curve, and neither does the frequency filter. We will deconvolve each of the curves from the previous deconvolution and plot the results. 

```{r}

#standard model inputs
shape=6.2
mean=5.6
scale=mean/shape
sd=sqrt(shape*scale^2)

parms <- c(mean,sd)
distribution <- "gamma"

infection_curve = as.data.frame(allchina, ncol=1)
for (i in 1:6) {
  new=deconvolve_single_curve(final_curve[,i], parms = parms, skip = c("random","ridge","fourier","frequency"))
  infection_curve=cbind(infection_curve, make_df(new, skip = c("random","ridge","fourier","frequency")))
}

# First column contains the original curve, the subsequent columns contain an estimation of the infection curve
plot(infection_curve[1:53,1], type='l', ylim=c(0.01,3000), log='y')
for (i in 2:length(infection_curve[1,])) {
  lines(infection_curve[1:53,i], type='l')
}
lines(infection_curve[1:53,1], type='l', ylim=c(0.01,3000), col='RED')

#tmpresults <- deconvolve_single_curve(curve = china$cases, parms = parms)

#china$I <- tmpresults$average

#plot(x=china$Date,y=china$cases, type="o",pch=20,cex=.7,main='Wuhan Outbreak Curves')
#lines(x=china$Date,y=china$I, type = 'o', pch=20,cex=.7,col="red")
#text(mean(china$Date),y=2000,labels="confirmed cases",col=1)
#text(mean(china$Date),y=1800,labels="Infected class I",col=2)

#save(tmpresults, file = "backcasting_I.rdata") #Rachel edit, to save results to file

# for(method in 1:length(deconvolutions)){
#         lines(deconvolutions[[method]],col=method+2,type="l")
# }
# text(5,y=360,labels="simple",col=3)
# text(5,y=340,labels="random",col=4)
# text(5,y=320,labels="ridge",col=5)
# text(5,y=300,labels="rl",col=6)
# text(5,y=290,labels="freq",col=7)


```

Since the deconvolution backs up the symptom-onset curve an average of 5.6 days, the last 7-8 days of the infection curve are not accurate due to the curve being truncated. Any sharp downward trend towards the end of the outbreak is likely due to errors from the truncated outbreak (run during the duration of the outbreak instead at the end looking back). Estimations should be good up until then, but not all the way to the last row of the dataframe. 

# Forecast Prep

```{r}
shape=6.2
mean=5.6
scale=mean/shape
sd=sqrt(shape*scale^2)

parms <- c(mean,sd)
distribution <- "gamma"

confidence_interval <- function(vector, interval) {
  vector=as.numeric(vector[1,])
  vec_sd <- sd(vector)
  n <- length(vector)
  vec_mean <- mean(vector)
  error <- qt((interval + 1)/2, df = n - 1) * vec_sd / sqrt(n)
  result <- c("lower" = vec_mean - error, "upper" = vec_mean + error)
  return(result)
}
results = deconvolve_single_curve(allchina, parms)
estimates = results$random_estimates
forecast = data.frame(curve = results$random)
forecast$lower = NA
forecast$upper = NA
for (i in 1:length(estimates[,1])) {
  ci = confidence_interval(estimates[i,1:length(estimates[1,])],0.95)
  forecast[i,"lower"] = ci[1]
  forecast[i,"upper"] = ci[2]
}

```

The data frame estimates has 35 estimates of the infection curve. If you would like to use that, wonderful. If not, the data frame forecast has the curve estimate with a 95% confidence interval.
